{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Identification\n",
    "\n",
    "Fake News, a real phenomenon that exists in every society. Hoaxes and propaganda heavily distorted people's perspective, making the iliterate a victim of misinformation that has real prominent harmful outcomes. With nowadays technology to spread information and several irresponsible parties in journalism industry, this has become a global event.\n",
    "\n",
    "This event not only impact but reigns over people perception & action to give highly negative effects towards society. And it's controlled by numbers of people behind the screen. Manual ways to identify a fake news is not an effective method towards this status quo. Therefore we need a sophisticated and high-end technology to offset current situation.\n",
    "\n",
    "Our idea is to use Artificial Intelligence to detect wether a news is considerable ```fake``` or ```real```. We thrive our best to build the greatest AI model by testing multiple algorithms and comparing multiple performance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why this dataset?\n",
    "\n",
    "1. Large amount of rows to increase our model accuracy.\n",
    "\n",
    "2. Content clarity\n",
    "\n",
    "3. Easy to manipulate (preprocessing needs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "We use ```pandas``` to read csv file\n",
    "\n",
    "\n",
    "\n",
    "We use ```string``` & ```re``` to preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ```sklearn``` to make instances of each algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use ```sklearn``` train the algorithm & measure each algo's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & Visualizing File\n",
    "\n",
    "These commands gives a quick preview about the data and label by adding ```class``` collumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake = pd.read_csv('datasets/Fake.csv')\n",
    "data_true = pd.read_csv('datasets/True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class col\n",
    "data_fake[\"class\"] = 0\n",
    "data_true[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing\n",
    "\n",
    "Take sample of the dataset to train ```manual testing``` method. and also label them the same way like we did on the datasets above.??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for manual testing\n",
    "data_fake_manual_testing = data_fake.iloc[-10:]\n",
    "data_true_manual_testing = data_true.iloc[-10:]\n",
    "\n",
    "# Drop data from original datasets\n",
    "data_fake = data_fake.iloc[:-10]\n",
    "data_true = data_true.iloc[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class col\n",
    "data_fake_manual_testing[\"class\"] = 0\n",
    "data_true_manual_testing[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true_manual_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge = pd.concat([data_fake,data_true], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_merge.drop(['title', 'subject', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Includes lower-casing each text, removing square bracketed text, replacing URLs with an empty string, removing HTML tags, stripping punctuation, and eliminating alphanumeric characters that contain digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    text = \"\".join(char if char.isalnum() or char.isspace() else \" \" for char in text)\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = \"\".join(char for char in text if char not in string.punctuation)\n",
    "    text = re.sub(r\"\\w*\\d\\w*\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data[\"text_length\"] = data[\"text\"].apply(len)\n",
    "\n",
    "# Plot scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for class_label in data[\"class\"].unique():\n",
    "    subset = data[data[\"class\"] == class_label]\n",
    "    plt.scatter(subset[\"text_length\"], subset[\"class\"], label=class_label)\n",
    "\n",
    "plt.title(\"Scatter Plot of Text Length vs. Class\")\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.legend(title=\"Class\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_distribution = data[\"class\"].value_counts()\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    class_distribution,\n",
    "    labels=class_distribution.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    ")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.axis(\"equal\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate word cloud for each class\n",
    "for label in data[\"class\"].unique():\n",
    "    text = \" \".join(data[data[\"class\"] == label][\"text\"])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\n",
    "        text\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.title(\"Word Cloud for Class {}\".format(label))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Includes:\n",
    "\n",
    "- Assigning $X$ and $Y$ axis with text and class respectively.\n",
    "\n",
    "- Splitting data for training and testing with a special random state (reproducibility).\n",
    "\n",
    "- Using ```TfidfVectorizer()``` to create a new matrix that will be used in algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(X_train)\n",
    "xv_test = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms & Visualization\n",
    "\n",
    "All of the algoritms respects the procedure as follows:\n",
    "\n",
    "1. *Create an instance* of the algorithm class\n",
    "\n",
    "2. Fitting the data for ```xv_train``` and ```y_train```\n",
    "\n",
    "3. Predict the data using ```xv_test```\n",
    "\n",
    "4. Create score for the model we train\n",
    "\n",
    "5. Make other performance indicator for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Logistic Regression: Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = LR.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Logistic Regression: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred_lr = LR.predict(xv_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = LR.score(xv_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, pred_lr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Decision Tree Classifier: Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt = DT.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Decision Tree Classifier: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(xv_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred_dt = DT.predict(xv_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = DT.score(xv_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, pred_dt)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - Decision Tree Classifiers\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Gradient Boost Classifier: Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(random_state=0)\n",
    "GB.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gb = GB.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Gradient Boost Classifier: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB.fit(xv_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred_GB = GB.predict(xv_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = GB.score(xv_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, pred_GB)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - Gradient Boost Classifier\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_GB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Random Forest Classifier:  Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(random_state=0)\n",
    "RF.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = RF.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Random Forest Classifier:  Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(xv_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred_rf = RF.predict(xv_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = RF.score(xv_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, pred_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - Random Forest Classifier\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional performance & data quality measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) k-fold and stratified k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, k=5, stratified=False):\n",
    "    if stratified:\n",
    "        kf = StratifiedKFold(n_splits=k)\n",
    "    else:\n",
    "        kf = KFold(n_splits=k)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = xv_train[train_index], xv_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    return avg_accuracy\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data_fake = pd.read_csv(\"datasets/Fake.csv\")\n",
    "data_true = pd.read_csv(\"datasets/True.csv\")\n",
    "\n",
    "# class column\n",
    "data_fake[\"class\"] = 0\n",
    "data_true[\"class\"] = 1\n",
    "\n",
    "# Get data for manual testing\n",
    "data_fake_manual_testing = data_fake.iloc[-10:]\n",
    "data_true_manual_testing = data_true.iloc[-10:]\n",
    "\n",
    "# Drop data from original datasets\n",
    "data_fake = data_fake.iloc[:-10]\n",
    "data_true = data_true.iloc[:-10]\n",
    "\n",
    "# class column\n",
    "data_fake_manual_testing[\"class\"] = 0\n",
    "data_true_manual_testing[\"class\"] = 1\n",
    "\n",
    "# Merge\n",
    "data_merge = pd.concat([data_fake, data_true], axis=0)\n",
    "data = data_merge.drop([\"title\", \"subject\", \"date\"], axis=1)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    text = \"\".join(char if char.isalnum() or char.isspace() else \" \" for char in text)\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = \"\".join(char for char in text if char not in string.punctuation)\n",
    "    text = re.sub(r\"\\w*\\d\\w*\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "data[\"text\"] = data[\"text\"].apply(clean_text)\n",
    "X = data[\"text\"]\n",
    "y = data[\"class\"]\n",
    "\n",
    "# Split data (test, train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=101\n",
    ")\n",
    "\n",
    "# Vectorize\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(X_train)\n",
    "xv_test = vectorization.transform(X_test)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "models = [LR, DT, RF]\n",
    "for model in models:\n",
    "    avg_accuracy = evaluate_model(model, xv_train, y_train, k=5, stratified=True)\n",
    "    print(\"Model:\", model.__class__.__name__)\n",
    "    print(\"Average accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Using cross_val_score and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "\n",
    "# Print average accuracy\n",
    "print(\"Average Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Train the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predictions on the test set\n",
    "pred_lr = pipeline.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, pred_lr)\n",
    "\n",
    "# Create heatmap for confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "# Create classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a parameter grid\n",
    "param_grid = {\n",
    "    \"clf__C\": [\n",
    "        0.001,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        1,\n",
    "        10,\n",
    "        100,\n",
    "    ],  # Regularization parameter for Logistic Regression\n",
    "}\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", LogisticRegression())])\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Using *manual test* to see if the outcome matches the actual result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lable(n):\n",
    "    if n == 0:\n",
    "        return \"Fake\"\n",
    "    elif n == 1:\n",
    "        return \"True\"\n",
    "    else:\n",
    "        return \"Unidentified\"\n",
    "    \n",
    "def manual_test(news):\n",
    "    testing_news = {\"text\":[news]}\n",
    "    new_def_test = pd.DataFrame(testing_news)\n",
    "    new_def_test['text'] = new_def_test[\"text\"].apply(clean_text)\n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    new_xv_test = vectorization.transform(new_x_test)\n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_DT = DT.predict(new_xv_test)\n",
    "    pred_GB = GB.predict(new_xv_test)\n",
    "    pred_RF = RF.predict(new_xv_test)\n",
    "    \n",
    "    return print(\"\\n\\nLR Predicition: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction:{}\".format(lable(pred_LR[0]),\n",
    "                                                                                                             lable(pred_DT[0]),\n",
    "                                                                                                             lable(pred_GB[0]),\n",
    "                                                                                                             lable(pred_RF[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = str(\n",
    "    \"21st Century Wire says This week, the historic international Iranian Nuclear Deal was punctuated by a two-way prisoner swap between Washington and Tehran, but it didn t end quite the way everyone expected. On the Iranian side, one of the U.S. citizens who was detained in Iran, Nosratollah Khosravi-Roodsari, has stayed in Iran, but on the U.S. side   all 7 of the Iranians held in U.S. prisons DID NOT show up to their flight to Geneva for the prisoner exchange   with at least 3 electing to stay in the U.S  TEHRAN SIDE: In Iran, 5 U.S. prisoners were released, with 4 of them making their way to Germany via Switzerland.Will Robinson Daily MailNone of the Iranians freed in the prisoner swap have returned home and could still be in the United States, it has been reported.The seven former inmates, who were released as part of a deal with the Islamic republic, did not show up to get a flight to Geneva, Switzerland, where the exchange was set to take place on Sunday.Three of the Iranians have decided to stay in the United States, ABC reported, with some moving in with their families. However it is not known where the other four are.Three of the Americans who had been detained in Iran   Washington Post journalist Jason Rezaian, former U.S. Marine Amir Hekmati and Christian pastor Saeed Abedini   left Tehran at around 7am the same day, but weren t met by their counterparts in Switzerland Continue this story at the Mail OnlineREAD MORE IRAN NEWS AT: 21st Century Wire Iran Files\"\n",
    ")\n",
    "manual_test(news)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
